{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a linear model with Estimators.\n",
    "This tutorial uses the tf.estimator API in TensorFlow to solve a benchmark binary classification problem. Estimators are TensorFlow's most scalable and production-oriented model type.\n",
    "\n",
    "## Overview\n",
    "Using census data which contains data a person's age, education, marital status, and occupation (the features), we will try to predict whether or not the person earns more than 50,000 dollars a year (the target label). We will train a logistic regression model that, given an individual's information, outputs a number between 0 and 1—this can be interpreted as the probability that the individual has an annual income of over 50,000 dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gmontes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Setup.\n",
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "# Download the official implementation.\n",
    "! pip install -q requests\n",
    "! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the root directory of the repository to the Python path.\n",
    "models_path = os.path.join(os.getcwd(), 'models')\n",
    "\n",
    "sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset.\n",
    "from official.wide_deep import census_dataset\n",
    "from official.wide_deep import census_main\n",
    "\n",
    "census_dataset.download(\"/tmp/census_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command line usage.\n",
    "if \"PYTHONPATH\" in os.environ:\n",
    "  os.environ['PYTHONPATH'] += os.pathsep +  models_path\n",
    "else:\n",
    "  os.environ['PYTHONPATH'] = models_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gmontes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Train DNN on census income dataset.\n",
      "flags:\n",
      "\n",
      "/Users/gmontes/Projects/Facultad/75.06 - Organización de Datos/TP1/75.06-Datos-Grupo22-TP1/tp2/TensorFlow/models/official/wide_deep/census_main.py:\n",
      "  -bs,--batch_size:\n",
      "    Batch size for training and evaluation. When using multiple gpus, this is\n",
      "    the\n",
      "    global batch size for all devices. For example, if the batch size is 32 and\n",
      "    there are 4 GPUs, each GPU will get 8 examples on each step.\n",
      "    (default: '40')\n",
      "    (an integer)\n",
      "  --[no]clean:\n",
      "    If set, model_dir will be removed if it exists.\n",
      "    (default: 'false')\n",
      "  -dd,--data_dir:\n",
      "    The location of the input data.\n",
      "    (default: '/tmp/census_data')\n",
      "  --[no]download_if_missing:\n",
      "    Download data to data_dir if it is not already present.\n",
      "    (default: 'true')\n",
      "  -ebe,--epochs_between_evals:\n",
      "    The number of training epochs to run between evaluations.\n",
      "    (default: '2')\n",
      "    (an integer)\n",
      "  -ed,--export_dir:\n",
      "    If set, a SavedModel serialization of the model will be exported to this\n",
      "    directory at the end of training. See the README for more details and\n",
      "    relevant\n",
      "    links.\n",
      "  -hk,--hooks:\n",
      "    A list of (case insensitive) strings to specify the names of training hooks.\n",
      "    ﻿  Hook:\n",
      "    ﻿    loggingtensorhook\n",
      "    ﻿    profilerhook\n",
      "    ﻿    examplespersecondhook\n",
      "    ﻿    loggingmetrichook\n",
      "    ﻿  Example: `--hooks ProfilerHook,ExamplesPerSecondHook`\n",
      "    See official.utils.logs.hooks_helper for details.\n",
      "    (default: 'LoggingTensorHook')\n",
      "    (a comma separated list)\n",
      "  -md,--model_dir:\n",
      "    The location of the model checkpoint files.\n",
      "    (default: '/tmp/census_model')\n",
      "  -mt,--model_type: <wide|deep|wide_deep>: Select model topology.\n",
      "    (default: 'wide_deep')\n",
      "  -te,--train_epochs:\n",
      "    The number of epochs used to train.\n",
      "    (default: '40')\n",
      "    (an integer)\n",
      "\n",
      "Try --helpfull to get a list of all flags.\n"
     ]
    }
   ],
   "source": [
    "!python -m official.wide_deep.census_main --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gmontes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "I0627 06:42:42.674832 4430263744 estimator.py:201] Using config: {'_model_dir': '/tmp/census_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "  value: 0\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb2c47ea90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "W0627 06:42:42.675733 4430263744 tf_logging.py:161] 'cpuinfo' not imported. CPU info will not be logged.\n",
      "2019-06-27 06:42:42.675931: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "I0627 06:42:42.718373 4430263744 logger.py:152] Benchmark run: {'model_name': 'wide_deep', 'dataset': {'name': 'Census Income'}, 'machine_config': {'gpu_info': {'count': 0}, 'memory_total': 17179869184, 'memory_available': 6365552640}, 'test_id': None, 'run_date': '2019-06-27T09:42:42.675306Z', 'tensorflow_version': {'version': '1.13.1', 'git_hash': \"b'unknown'\"}, 'tensorflow_environment_variables': [], 'run_parameters': [{'name': 'batch_size', 'long_value': 40}, {'name': 'model_type', 'string_value': 'wide'}, {'name': 'train_epochs', 'long_value': 2}]}\n",
      "W0627 06:42:42.744343 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "I0627 06:42:42.756781 4430263744 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n",
      "I0627 06:42:42.791178 4430263744 estimator.py:1111] Calling model_fn.\n",
      "W0627 06:42:42.834938 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0627 06:42:42.850497 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2898: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "I0627 06:42:43.663021 4430263744 estimator.py:1113] Done calling model_fn.\n",
      "I0627 06:42:43.663202 4430263744 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n",
      "I0627 06:42:44.005892 4430263744 monitored_session.py:222] Graph was finalized.\n",
      "2019-06-27 06:42:44.006116: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 12. Tune using inter_op_parallelism_threads for best performance.\n",
      "W0627 06:42:44.009546 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0627 06:42:44.010715 4430263744 saver.py:1270] Restoring parameters from /tmp/census_model/model.ckpt-4887\n",
      "W0627 06:42:44.113509 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "I0627 06:42:44.180130 4430263744 session_manager.py:491] Running local_init_op.\n",
      "I0627 06:42:44.216180 4430263744 session_manager.py:493] Done running local_init_op.\n",
      "I0627 06:42:44.875725 4430263744 basic_session_run_hooks.py:594] Saving checkpoints for 4887 into /tmp/census_model/model.ckpt.\n",
      "I0627 06:42:46.334393 4430263744 basic_session_run_hooks.py:249] average_loss = 0.36241764, loss = 14.496706\n",
      "I0627 06:42:46.334578 4430263744 basic_session_run_hooks.py:249] loss = 14.496706, step = 4888\n",
      "I0627 06:42:48.142098 4430263744 basic_session_run_hooks.py:680] global_step/sec: 55.3112\n",
      "I0627 06:42:48.142446 4430263744 basic_session_run_hooks.py:247] average_loss = 0.37632155, loss = 15.052862 (1.808 sec)\n",
      "I0627 06:42:48.142543 4430263744 basic_session_run_hooks.py:247] loss = 15.052862, step = 4988 (1.808 sec)\n",
      "I0627 06:42:49.026806 4430263744 basic_session_run_hooks.py:680] global_step/sec: 113.032\n",
      "I0627 06:42:49.027252 4430263744 basic_session_run_hooks.py:247] average_loss = 0.27104616, loss = 10.841846 (0.885 sec)\n",
      "I0627 06:42:49.027408 4430263744 basic_session_run_hooks.py:247] loss = 10.841846, step = 5088 (0.885 sec)\n",
      "I0627 06:42:49.927395 4430263744 basic_session_run_hooks.py:680] global_step/sec: 111.038\n",
      "I0627 06:42:49.927760 4430263744 basic_session_run_hooks.py:247] average_loss = 0.2944395, loss = 11.777579 (0.901 sec)\n",
      "I0627 06:42:49.927861 4430263744 basic_session_run_hooks.py:247] loss = 11.777579, step = 5188 (0.900 sec)\n",
      "I0627 06:42:50.820394 4430263744 basic_session_run_hooks.py:680] global_step/sec: 111.982\n",
      "I0627 06:42:50.820748 4430263744 basic_session_run_hooks.py:247] average_loss = 0.4713067, loss = 18.852268 (0.893 sec)\n",
      "I0627 06:42:50.820891 4430263744 basic_session_run_hooks.py:247] loss = 18.852268, step = 5288 (0.893 sec)\n",
      "I0627 06:42:51.731061 4430263744 basic_session_run_hooks.py:680] global_step/sec: 109.81\n",
      "I0627 06:42:51.731481 4430263744 basic_session_run_hooks.py:247] average_loss = 0.31012636, loss = 12.405054 (0.911 sec)\n",
      "I0627 06:42:51.731624 4430263744 basic_session_run_hooks.py:247] loss = 12.405054, step = 5388 (0.911 sec)\n",
      "I0627 06:42:52.660681 4430263744 basic_session_run_hooks.py:680] global_step/sec: 107.571\n",
      "I0627 06:42:52.661040 4430263744 basic_session_run_hooks.py:247] average_loss = 0.21274805, loss = 8.509922 (0.930 sec)\n",
      "I0627 06:42:52.661142 4430263744 basic_session_run_hooks.py:247] loss = 8.509922, step = 5488 (0.930 sec)\n",
      "I0627 06:42:53.607735 4430263744 basic_session_run_hooks.py:680] global_step/sec: 105.591\n",
      "I0627 06:42:53.608086 4430263744 basic_session_run_hooks.py:247] average_loss = 0.25577828, loss = 10.231132 (0.947 sec)\n",
      "I0627 06:42:53.608186 4430263744 basic_session_run_hooks.py:247] loss = 10.231132, step = 5588 (0.947 sec)\n",
      "I0627 06:42:54.580070 4430263744 basic_session_run_hooks.py:680] global_step/sec: 102.845\n",
      "I0627 06:42:54.580481 4430263744 basic_session_run_hooks.py:247] average_loss = 0.21479759, loss = 8.591904 (0.972 sec)\n",
      "I0627 06:42:54.580634 4430263744 basic_session_run_hooks.py:247] loss = 8.591904, step = 5688 (0.972 sec)\n",
      "I0627 06:42:55.719579 4430263744 basic_session_run_hooks.py:680] global_step/sec: 87.7569\n",
      "I0627 06:42:55.719942 4430263744 basic_session_run_hooks.py:247] average_loss = 0.31140226, loss = 12.456091 (1.139 sec)\n",
      "I0627 06:42:55.720052 4430263744 basic_session_run_hooks.py:247] loss = 12.456091, step = 5788 (1.139 sec)\n",
      "I0627 06:42:56.719738 4430263744 basic_session_run_hooks.py:680] global_step/sec: 99.9851\n",
      "I0627 06:42:56.720165 4430263744 basic_session_run_hooks.py:247] average_loss = 0.17935097, loss = 7.174039 (1.000 sec)\n",
      "I0627 06:42:56.720314 4430263744 basic_session_run_hooks.py:247] loss = 7.174039, step = 5888 (1.000 sec)\n",
      "I0627 06:42:57.702298 4430263744 basic_session_run_hooks.py:680] global_step/sec: 101.774\n",
      "I0627 06:42:57.702677 4430263744 basic_session_run_hooks.py:247] average_loss = 0.34770882, loss = 13.908353 (0.983 sec)\n",
      "I0627 06:42:57.702792 4430263744 basic_session_run_hooks.py:247] loss = 13.908353, step = 5988 (0.982 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0627 06:42:58.712058 4430263744 basic_session_run_hooks.py:680] global_step/sec: 99.0343\n",
      "I0627 06:42:58.712459 4430263744 basic_session_run_hooks.py:247] average_loss = 0.33914065, loss = 13.565626 (1.010 sec)\n",
      "I0627 06:42:58.712664 4430263744 basic_session_run_hooks.py:247] loss = 13.565626, step = 6088 (1.010 sec)\n",
      "I0627 06:42:59.722688 4430263744 basic_session_run_hooks.py:680] global_step/sec: 98.9479\n",
      "I0627 06:42:59.723067 4430263744 basic_session_run_hooks.py:247] average_loss = 0.38155884, loss = 15.262354 (1.011 sec)\n",
      "I0627 06:42:59.723221 4430263744 basic_session_run_hooks.py:247] loss = 15.262354, step = 6188 (1.011 sec)\n",
      "I0627 06:43:00.759825 4430263744 basic_session_run_hooks.py:680] global_step/sec: 96.4192\n",
      "I0627 06:43:00.760270 4430263744 basic_session_run_hooks.py:247] average_loss = 0.33988985, loss = 13.595594 (1.037 sec)\n",
      "I0627 06:43:00.760413 4430263744 basic_session_run_hooks.py:247] loss = 13.595594, step = 6288 (1.037 sec)\n",
      "I0627 06:43:01.758954 4430263744 basic_session_run_hooks.py:680] global_step/sec: 100.087\n",
      "I0627 06:43:01.759320 4430263744 basic_session_run_hooks.py:247] average_loss = 0.37778383, loss = 15.111353 (0.999 sec)\n",
      "I0627 06:43:01.759422 4430263744 basic_session_run_hooks.py:247] loss = 15.111353, step = 6388 (0.999 sec)\n",
      "I0627 06:43:02.752295 4430263744 basic_session_run_hooks.py:680] global_step/sec: 100.67\n",
      "I0627 06:43:02.752671 4430263744 basic_session_run_hooks.py:247] average_loss = 0.42635196, loss = 17.05408 (0.993 sec)\n",
      "I0627 06:43:02.752779 4430263744 basic_session_run_hooks.py:247] loss = 17.05408, step = 6488 (0.993 sec)\n",
      "I0627 06:43:03.050222 4430263744 basic_session_run_hooks.py:594] Saving checkpoints for 6516 into /tmp/census_model/model.ckpt.\n",
      "I0627 06:43:03.216834 4430263744 estimator.py:359] Loss for final step: 0.81208295.\n",
      "I0627 06:43:03.225224 4430263744 census_dataset.py:167] Parsing /tmp/census_data/adult.test\n",
      "I0627 06:43:03.247459 4430263744 estimator.py:1111] Calling model_fn.\n",
      "W0627 06:43:03.995965 4430263744 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0627 06:43:04.271327 4430263744 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "W0627 06:43:04.286057 4430263744 metrics_impl.py:783] Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "I0627 06:43:04.301256 4430263744 estimator.py:1113] Done calling model_fn.\n",
      "I0627 06:43:04.315140 4430263744 evaluation.py:257] Starting evaluation at 2019-06-27T09:43:04Z\n",
      "I0627 06:43:04.479444 4430263744 monitored_session.py:222] Graph was finalized.\n",
      "I0627 06:43:04.481072 4430263744 saver.py:1270] Restoring parameters from /tmp/census_model/model.ckpt-6516\n",
      "I0627 06:43:04.622694 4430263744 session_manager.py:491] Running local_init_op.\n",
      "I0627 06:43:04.706387 4430263744 session_manager.py:493] Done running local_init_op.\n",
      "I0627 06:43:09.178421 4430263744 evaluation.py:277] Finished evaluation at 2019-06-27-09:43:09\n",
      "I0627 06:43:09.178570 4430263744 estimator.py:1979] Saving dict for global step 6516: accuracy = 0.8353909, accuracy_baseline = 0.76377374, auc = 0.88216746, auc_precision_recall = 0.69261014, average_loss = 0.3535871, global_step = 6516, label/mean = 0.23622628, loss = 14.109685, precision = 0.69114757, prediction/mean = 0.23468782, recall = 0.5481019\n",
      "I0627 06:43:09.420085 4430263744 estimator.py:2039] Saving 'checkpoint_path' summary for global step 6516: /tmp/census_model/model.ckpt-6516\n",
      "I0627 06:43:09.420411 4430263744 wide_deep_run_loop.py:116] Results at epoch 2 / 2\n",
      "I0627 06:43:09.420469 4430263744 wide_deep_run_loop.py:117] ------------------------------------------------------------\n",
      "I0627 06:43:09.420516 4430263744 wide_deep_run_loop.py:120] accuracy: 0.8353909\n",
      "I0627 06:43:09.420552 4430263744 wide_deep_run_loop.py:120] accuracy_baseline: 0.76377374\n",
      "I0627 06:43:09.420588 4430263744 wide_deep_run_loop.py:120] auc: 0.88216746\n",
      "I0627 06:43:09.420622 4430263744 wide_deep_run_loop.py:120] auc_precision_recall: 0.69261014\n",
      "I0627 06:43:09.420661 4430263744 wide_deep_run_loop.py:120] average_loss: 0.3535871\n",
      "I0627 06:43:09.420698 4430263744 wide_deep_run_loop.py:120] global_step: 6516\n",
      "I0627 06:43:09.420730 4430263744 wide_deep_run_loop.py:120] label/mean: 0.23622628\n",
      "I0627 06:43:09.420762 4430263744 wide_deep_run_loop.py:120] loss: 14.109685\n",
      "I0627 06:43:09.420794 4430263744 wide_deep_run_loop.py:120] precision: 0.69114757\n",
      "I0627 06:43:09.420826 4430263744 wide_deep_run_loop.py:120] prediction/mean: 0.23468782\n",
      "I0627 06:43:09.420858 4430263744 wide_deep_run_loop.py:120] recall: 0.5481019\n",
      "I0627 06:43:09.420937 4430263744 logger.py:147] Benchmark metric: {'name': 'accuracy', 'value': 0.8353909254074097, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.420914Z', 'extras': []}\n",
      "I0627 06:43:09.421001 4430263744 logger.py:147] Benchmark metric: {'name': 'accuracy_baseline', 'value': 0.7637737393379211, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.420988Z', 'extras': []}\n",
      "I0627 06:43:09.421057 4430263744 logger.py:147] Benchmark metric: {'name': 'auc', 'value': 0.8821674585342407, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421045Z', 'extras': []}\n",
      "I0627 06:43:09.421111 4430263744 logger.py:147] Benchmark metric: {'name': 'auc_precision_recall', 'value': 0.6926101446151733, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421099Z', 'extras': []}\n",
      "I0627 06:43:09.421163 4430263744 logger.py:147] Benchmark metric: {'name': 'average_loss', 'value': 0.3535870909690857, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421151Z', 'extras': []}\n",
      "I0627 06:43:09.421213 4430263744 logger.py:147] Benchmark metric: {'name': 'label/mean', 'value': 0.23622627556324005, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421203Z', 'extras': []}\n",
      "I0627 06:43:09.421264 4430263744 logger.py:147] Benchmark metric: {'name': 'loss', 'value': 14.109684944152832, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421254Z', 'extras': []}\n",
      "I0627 06:43:09.421316 4430263744 logger.py:147] Benchmark metric: {'name': 'precision', 'value': 0.6911475658416748, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421305Z', 'extras': []}\n",
      "I0627 06:43:09.421365 4430263744 logger.py:147] Benchmark metric: {'name': 'prediction/mean', 'value': 0.23468782007694244, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421355Z', 'extras': []}\n",
      "I0627 06:43:09.421416 4430263744 logger.py:147] Benchmark metric: {'name': 'recall', 'value': 0.5481019020080566, 'unit': None, 'global_step': 6516, 'timestamp': '2019-06-27T09:43:09.421406Z', 'extras': []}\n"
     ]
    }
   ],
   "source": [
    "# Now run the model.\n",
    "!python -m official.wide_deep.census_main --model_type=wide --train_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.data adult.test\r\n"
     ]
    }
   ],
   "source": [
    "# Read the U.S. Census data.\n",
    "# Since the task is a binary classification problem, \n",
    "# we'll construct a label column named \"label\" whose value is 1 if the income is over 50K, and 0 otherwise.\n",
    "!ls  /tmp/census_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"/tmp/census_data/adult.data\"\n",
    "test_file = \"/tmp/census_data/adult.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race  gender  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_bracket  \n",
       "0          2174             0              40  United-States          <=50K  \n",
       "1             0             0              13  United-States          <=50K  \n",
       "2             0             0              40  United-States          <=50K  \n",
       "3             0             0              40  United-States          <=50K  \n",
       "4             0             0              40           Cuba          <=50K  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "train_df = pandas.read_csv(train_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
    "test_df = pandas.read_csv(test_file, header = None, names = census_dataset._CSV_COLUMNS)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Data into Tensors\n",
    "When building a tf.estimator model, the input data is specified by using an input function (or input_fn). This builder function returns a tf.data.Dataset of batches of (features-dict, label) pairs. It is not called until it is passed to tf.estimator.Estimator methods such as train and evaluate.\n",
    "\n",
    "The input builder function returns the following pair:\n",
    "\n",
    "1 - features: A dict from feature names to Tensors or SparseTensors containing batches of features.\n",
    "\n",
    "2 - labels: A Tensor containing batches of labels.\n",
    "\n",
    "The keys of the features are used to configure the model's input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For small problems like this, it's easy to make a tf.data.Dataset by slicing the pandas.DataFrame.\n",
    "def easy_input_function(df, label_key, num_epochs, shuffle, batch_size):\n",
    "  label = df[label_key]\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(df),label))\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(10000)\n",
    "\n",
    "  ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0627 06:43:10.142467 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
      "\n",
      "A batch of Ages  : tf.Tensor([18 51 37 28 32 39 32 52 46 22], shape=(10,), dtype=int32)\n",
      "\n",
      "A batch of Labels: tf.Tensor(\n",
      "[b'<=50K' b'>50K' b'>50K' b'<=50K' b'>50K' b'<=50K' b'<=50K' b'<=50K'\n",
      " b'<=50K' b'<=50K'], shape=(10,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Since we have eager execution enabled, it's easy to inspect the resulting dataset.\n",
    "ds = easy_input_function(train_df, label_key='income_bracket', num_epochs=5, shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "  print('Some feature keys:', list(feature_batch.keys())[:5])\n",
    "  print()\n",
    "  print('A batch of Ages  :', feature_batch['age'])\n",
    "  print()\n",
    "  print('A batch of Labels:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
      "  \"\"\"Generate an input function for the Estimator.\"\"\"\n",
      "  assert tf.gfile.Exists(data_file), (\n",
      "      '%s not found. Please make sure you have run census_dataset.py and '\n",
      "      'set the --data_dir argument to the correct path.' % data_file)\n",
      "\n",
      "  def parse_csv(value):\n",
      "    tf.logging.info('Parsing {}'.format(data_file))\n",
      "    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
      "    features = dict(zip(_CSV_COLUMNS, columns))\n",
      "    labels = features.pop('income_bracket')\n",
      "    classes = tf.equal(labels, '>50K')  # binary classification\n",
      "    return features, classes\n",
      "\n",
      "  # Extract lines from input files using the Dataset API.\n",
      "  dataset = tf.data.TextLineDataset(data_file)\n",
      "\n",
      "  if shuffle:\n",
      "    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])\n",
      "\n",
      "  dataset = dataset.map(parse_csv, num_parallel_calls=5)\n",
      "\n",
      "  # We call repeat after shuffling, rather than before, to prevent separate\n",
      "  # epochs from blending together.\n",
      "  dataset = dataset.repeat(num_epochs)\n",
      "  dataset = dataset.batch(batch_size)\n",
      "  return dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# But this approach has severly-limited scalability. \n",
    "# Larger datasets should be streamed from disk. \n",
    "# The census_dataset.input_fn provides an example of how to do this using tf.decode_csv and tf.data.TextLineDataset.\n",
    "import inspect\n",
    "print(inspect.getsource(census_dataset.input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Parsing /tmp/census_data/adult.data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 06:43:10.530493 4650505664 census_dataset.py:167] Parsing /tmp/census_data/adult.data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature keys: ['age', 'workclass', 'fnlwgt', 'education', 'education_num']\n",
      "\n",
      "Age batch   : tf.Tensor([30 63 42 43 26 36 21 69 28 33], shape=(10,), dtype=int32)\n",
      "\n",
      "Label batch : tf.Tensor([False False False False False False False False False False], shape=(10,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "ds = census_dataset.input_fn(train_file, num_epochs=5, shuffle=True, batch_size=10)\n",
    "\n",
    "for feature_batch, label_batch in ds.take(1):\n",
    "  print('Feature keys:', list(feature_batch.keys())[:5])\n",
    "  print()\n",
    "  print('Age batch   :', feature_batch['age'])\n",
    "  print()\n",
    "  print('Label batch :', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because Estimators expect an input_fn that takes no arguments, we typically wrap configurable input function \n",
    "# into an obejct with the expected signature. \n",
    "# For this notebook configure the train_inpf to iterate over the data twice.\n",
    "import functools\n",
    "\n",
    "train_inpf = functools.partial(census_dataset.input_fn, train_file, num_epochs=2, shuffle=True, batch_size=64)\n",
    "test_inpf = functools.partial(census_dataset.input_fn, test_file, num_epochs=1, shuffle=False, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting and Engineering Features for the Model\n",
    "Estimators use a system called feature columns to describe how the model should interpret each of the raw input features. An Estimator expects a vector of numeric inputs, and feature columns describe how the model should convert each feature.\n",
    "\n",
    "Selecting and crafting the right set of feature columns is key to learning an effective model. A feature column can be either one of the raw inputs in the original features dict (a base feature column), or any new columns created using transformations defined over one or multiple base columns (a derived feature columns).\n",
    "\n",
    "A feature column is an abstract concept of any raw or derived variable that can be used to predict the target label.\n",
    "\n",
    "### Base Feature Columns\n",
    "#### Numeric columns\n",
    "The simplest feature_column is numeric_column. This indicates that a feature is a numeric value that should be input to the model directly. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:10.755248 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:10.756400 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:10.758100 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:10.759333 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=136, shape=(10, 1), dtype=float32, numpy=\n",
       "array([[30.],\n",
       "       [63.],\n",
       "       [42.],\n",
       "       [43.],\n",
       "       [26.],\n",
       "       [36.],\n",
       "       [21.],\n",
       "       [69.],\n",
       "       [28.],\n",
       "       [33.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = fc.numeric_column('age')\n",
    "\n",
    "# The model will use the feature_column definitions to build the model input. \n",
    "# You can inspect the resulting output using the input_layer function.\n",
    "fc.input_layer(feature_batch, [age])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7562189, 'accuracy_baseline': 0.76377374, 'auc': 0.6783409, 'auc_precision_recall': 0.3113884, 'average_loss': 0.5238994, 'label/mean': 0.23622628, 'loss': 33.449432, 'precision': 0.16756757, 'prediction/mean': 0.25558934, 'recall': 0.008060322, 'global_step': 1018}\n"
     ]
    }
   ],
   "source": [
    "# The following will train and evaluate a model using only the age feature.\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=[age])\n",
    "classifier.train(train_inpf)\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "clear_output()  # used for display in notebook\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2129, shape=(10, 5), dtype=float32, numpy=\n",
       "array([[  30.,    0.,    0.,    9.,   40.],\n",
       "       [  63.,    0.,    0.,   10.,   12.],\n",
       "       [  42.,    0.,    0.,    9.,   15.],\n",
       "       [  43.,    0.,    0.,   14.,   55.],\n",
       "       [  26., 3325.,    0.,   13.,   40.],\n",
       "       [  36.,    0.,    0.,    9.,   38.],\n",
       "       [  21.,    0.,    0.,    9.,   60.],\n",
       "       [  69.,    0.,    0.,   14.,   25.],\n",
       "       [  28.,    0., 2002.,   12.,   40.],\n",
       "       [  33.,    0.,    0.,   13.,   60.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly, we can define a NumericColumn for each continuous feature column that we want to use in the model.\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "my_numeric_columns = [age,education_num, capital_gain, capital_loss, hours_per_week]\n",
    "\n",
    "fc.input_layer(feature_batch, my_numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7815245\n",
      "accuracy_baseline: 0.76377374\n",
      "auc: 0.795743\n",
      "auc_precision_recall: 0.55417717\n",
      "average_loss: 1.755469\n",
      "global_step: 1018\n",
      "label/mean: 0.23622628\n",
      "loss: 112.081535\n",
      "precision: 0.56943774\n",
      "prediction/mean: 0.31169283\n",
      "recall: 0.30811232\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns)\n",
    "classifier.train(train_inpf)\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for key,value in sorted(result.items()):\n",
    "  print('%s: %s' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns\n",
    "To define a feature column for a categorical feature, create a CategoricalColumn using one of the tf.feature_column.categorical_column* functions.\n",
    "\n",
    "If you know the set of all possible feature values of a column—and there are only a few of them—use categorical_column_with_vocabulary_list. Each key in the list is assigned an auto-incremented ID starting from 0. For example, for the relationship column we can assign the feature string Husband to an integer ID of 0 and \"Not-in-family\" to 1, etc.\n",
    "\n",
    "This creates a sparse one-hot vector from the raw input feature.\n",
    "\n",
    "The input_layer function we're using is designed for DNN models and expects dense inputs. To demonstrate the categorical column we must wrap it in a tf.feature_column.indicator_column to create the dense one-hot output (Linear Estimators can often skip this dense-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.216730 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: IndicatorColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.218270 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: IndicatorColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.220144 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: VocabularyListCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.221554 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: VocabularyListCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.224778 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.227194 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4266: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.228356 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4866, shape=(10, 7), dtype=float32, numpy=\n",
       "array([[30.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [63.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [42.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [43.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [26.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [36.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [21.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [69.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [28.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [33.,  0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship = fc.categorical_column_with_vocabulary_list(\n",
    "    'relationship',\n",
    "    ['Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'])\n",
    "\n",
    "fc.input_layer(feature_batch, [age, fc.indicator_column(relationship)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transport-moving\n",
      "Prof-specialty\n",
      "Farming-fishing\n",
      "Prof-specialty\n",
      "Craft-repair\n",
      "Adm-clerical\n",
      "Exec-managerial\n",
      "Prof-specialty\n",
      "Protective-serv\n",
      "Protective-serv\n"
     ]
    }
   ],
   "source": [
    "# If we don't know the set of possible values in advance, use the categorical_column_with_hash_bucket instead.\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    'occupation', hash_bucket_size=1000)\n",
    "\n",
    "# Here, each possible value in the feature column occupation is hashed to an integer ID as we encounter \n",
    "# them in training.\n",
    "for item in feature_batch['occupation'].numpy():\n",
    "    print(item.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.241648 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4295: HashedCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.242828 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: HashedCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:43:52.244911 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:4321: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_result = fc.input_layer(feature_batch, [fc.indicator_column(occupation)])\n",
    "\n",
    "occupation_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([420, 979, 936, 979, 466,  96, 800, 979, 684, 684])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(occupation_result, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter how we choose to define a SparseColumn, each feature string is mapped into an integer ID by looking up a fixed mapping or by hashing. Under the hood, the LinearModel class is responsible for managing the mapping and creating tf.Variable to store the model parameters (model weights) for each feature ID. The model parameters are learned through the model training process described later.\n",
    "\n",
    "Let's do the similar trick to define the other categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'education', [\n",
    "        'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
    "        'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
    "        '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
    "\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'marital_status', [\n",
    "        'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
    "        'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
    "\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'workclass', [\n",
    "        'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
    "        'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
    "\n",
    "\n",
    "my_categorical_columns = [relationship, occupation, education, marital_status, workclass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82003564\n",
      "accuracy_baseline: 0.76377374\n",
      "auc: 0.8219939\n",
      "auc_precision_recall: 0.61432624\n",
      "average_loss: 0.93544346\n",
      "global_step: 1018\n",
      "label/mean: 0.23622628\n",
      "loss: 59.725315\n",
      "precision: 0.6433041\n",
      "prediction/mean: 0.22795415\n",
      "recall: 0.53458136\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=my_numeric_columns+my_categorical_columns)\n",
    "classifier.train(train_inpf)\n",
    "result = classifier.evaluate(test_inpf)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for key,value in sorted(result.items()):\n",
    "  print('%s: %s' % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived feature columns\n",
    "#### Make Continuous Features Categorical through Bucketization\n",
    "Sometimes the relationship between a continuous feature and the label is not linear. For example, age and income—a person's income may grow in the early stage of their career, then the growth may slow at some point, and finally, the income decreases after retirement. In this scenario, using the raw age as a real-valued feature column might not be a good choice because the model can only learn one of the three cases:\n",
    "\n",
    "1 - Income always increases at some rate as age grows (positive correlation),\n",
    "\n",
    "2 - Income always decreases at some rate as age grows (negative correlation), or\n",
    "\n",
    "3 - Income stays the same no matter at what age (no correlation).\n",
    "\n",
    "If we want to learn the fine-grained correlation between income and each age group separately, we can leverage bucketization. Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into. So, we can define a bucketized_column over age as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BucketizedColumn(source_column=NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "age_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: BucketizedColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:44:18.555160 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:205: BucketizedColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: BucketizedColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:44:18.556488 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:2121: BucketizedColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:206: BucketizedColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0627 06:44:18.558437 4650505664 deprecation.py:323] From /Users/gmontes/anaconda3/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py:206: BucketizedColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9435, shape=(10, 12), dtype=float32, numpy=\n",
       "array([[30.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [63.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "       [42.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [43.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [26.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [36.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [21.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [69.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [28.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [33.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With bucketing, the model sees each bucket a one-hot feature.\n",
    "fc.input_layer(feature_batch, [age, age_buckets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn complex relationships with crossed column\n",
    "Using each base feature column separately may not be enough to explain the data. For example, the correlation between education and the label (earning > 50,000 dollars) may be different for different occupations. Therefore, if we only learn a single model weight for education=\"Bachelors\" and education=\"Masters\", we won't capture every education-occupation combination (e.g. distinguishing between education=\"Bachelors\" AND occupation=\"Exec-managerial\" AND education=\"Bachelors\" AND occupation=\"Craft-repair\").\n",
    "\n",
    "To learn the differences between different feature combinations, we can add crossed feature columns to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_x_occupation = tf.feature_column.crossed_column(\n",
    "    ['education', 'occupation'], hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also create a crossed_column over more than two columns. \n",
    "# Each constituent column can be either a base feature column that is categorical (SparseColumn), \n",
    "# a bucketized real-valued feature column, or even another CrossColumn.\n",
    "# These crossed columns always use hash buckets to avoid the exponential explosion in the number of categories, \n",
    "# and put the control over number of model weights in the hands of the user.\n",
    "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(\n",
    "    [age_buckets, 'education', 'occupation'], hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the logistic regression model\n",
    "After processing the input data and defining all the feature columns, we can put them together and build a logistic regression model. The previous section showed several types of base and derived feature columns, including:\n",
    "\n",
    "- CategoricalColumn\n",
    "- NumericColumn\n",
    "- BucketizedColumn\n",
    "- CrossedColumn\n",
    "\n",
    "All of these are subclasses of the abstract FeatureColumn class and can be added to the feature_columns field of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 06:44:18.579401 4650505664 estimator.py:1739] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/k8/jlk2vp8n2q1cb314v8ypl_dw0000gp/T/tmpfnl1gd1u', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb33827860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 06:44:18.580864 4650505664 estimator.py:201] Using config: {'_model_dir': '/var/folders/k8/jlk2vp8n2q1cb314v8ypl_dw0000gp/T/tmpfnl1gd1u', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb33827860>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "base_columns = [\n",
    "    education, marital_status, relationship, workclass, occupation,\n",
    "    age_buckets,\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "        ['education', 'occupation'], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [age_buckets, 'education', 'occupation'], hash_bucket_size=1000),\n",
    "]\n",
    "\n",
    "model = tf.estimator.LinearClassifier(\n",
    "    model_dir=tempfile.mkdtemp(), \n",
    "    feature_columns=base_columns + crossed_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inpf = functools.partial(census_dataset.input_fn, train_file, \n",
    "                               num_epochs=40, shuffle=True, batch_size=64)\n",
    "\n",
    "model.train(train_inpf)\n",
    "\n",
    "clear_output()  # used for notebook display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n",
      "accuracy_baseline: 0.76\n",
      "auc: 0.82\n",
      "auc_precision_recall: 0.61\n",
      "average_loss: 0.94\n",
      "global_step: 1018.00\n",
      "label/mean: 0.24\n",
      "loss: 59.73\n",
      "precision: 0.64\n",
      "prediction/mean: 0.23\n",
      "recall: 0.53\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_inpf)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for key,value in sorted(result.items()):\n",
    "  print('%s: %0.2f' % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income_bracket</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income_bracket predicted_class  correct\n",
       "0           <=50K           <=50K     True\n",
       "1           <=50K           <=50K     True\n",
       "2            >50K           <=50K    False\n",
       "3            >50K           <=50K    False\n",
       "4           <=50K           <=50K     True\n",
       "5           <=50K           <=50K     True\n",
       "6           <=50K           <=50K     True\n",
       "7            >50K            >50K     True\n",
       "8           <=50K           <=50K     True\n",
       "9           <=50K           <=50K     True\n",
       "10           >50K           <=50K    False\n",
       "11          <=50K            >50K    False\n",
       "12          <=50K           <=50K     True\n",
       "13          <=50K           <=50K     True\n",
       "14           >50K           <=50K    False\n",
       "15           >50K            >50K     True\n",
       "16          <=50K           <=50K     True\n",
       "17          <=50K           <=50K     True\n",
       "18          <=50K           <=50K     True\n",
       "19           >50K            >50K     True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After the model is evaluated, we can use it to predict whether an individual has an annual income of over \n",
    "# 50,000 dollars given an individual's information input.\n",
    "import numpy as np\n",
    "\n",
    "predict_df = test_df[:20].copy()\n",
    "\n",
    "pred_iter = model.predict(\n",
    "    lambda:easy_input_function(predict_df, label_key='income_bracket',\n",
    "                               num_epochs=1, shuffle=False, batch_size=10))\n",
    "\n",
    "classes = np.array(['<=50K', '>50K'])\n",
    "pred_class_id = []\n",
    "\n",
    "for pred_dict in pred_iter:\n",
    "  pred_class_id.append(pred_dict['class_ids'])\n",
    "\n",
    "predict_df['predicted_class'] = classes[np.array(pred_class_id)]\n",
    "predict_df['correct'] = predict_df['predicted_class'] == predict_df['income_bracket']\n",
    "\n",
    "clear_output()\n",
    "\n",
    "predict_df[['income_bracket','predicted_class', 'correct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Regularization to Prevent Overfitting\n",
    "Regularization is a technique used to avoid overfitting. Overfitting happens when a model performs well on the data it is trained on, but worse on test data that the model has not seen before. Overfitting can occur when a model is excessively complex, such as having too many parameters relative to the number of observed training data. Regularization allows you to control the model's complexity and make the model more generalizable to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84\n",
      "accuracy_baseline: 0.76\n",
      "auc: 0.88\n",
      "auc_precision_recall: 0.69\n",
      "average_loss: 0.35\n",
      "global_step: 20351.00\n",
      "label/mean: 0.24\n",
      "loss: 22.47\n",
      "precision: 0.69\n",
      "prediction/mean: 0.24\n",
      "recall: 0.57\n"
     ]
    }
   ],
   "source": [
    "model_l1 = tf.estimator.LinearClassifier(\n",
    "    feature_columns=base_columns + crossed_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=10.0,\n",
    "        l2_regularization_strength=0.0))\n",
    "\n",
    "model_l1.train(train_inpf)\n",
    "\n",
    "results = model_l1.evaluate(test_inpf)\n",
    "clear_output()\n",
    "for key in sorted(results):\n",
    "  print('%s: %0.2f' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.84\n",
      "accuracy_baseline: 0.76\n",
      "auc: 0.88\n",
      "auc_precision_recall: 0.69\n",
      "average_loss: 0.35\n",
      "global_step: 20351.00\n",
      "label/mean: 0.24\n",
      "loss: 22.46\n",
      "precision: 0.69\n",
      "prediction/mean: 0.24\n",
      "recall: 0.55\n"
     ]
    }
   ],
   "source": [
    "model_l2 = tf.estimator.LinearClassifier(\n",
    "    feature_columns=base_columns + crossed_columns,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "        learning_rate=0.1,\n",
    "        l1_regularization_strength=0.0,\n",
    "        l2_regularization_strength=10.0))\n",
    "\n",
    "model_l2.train(train_inpf)\n",
    "\n",
    "results = model_l2.evaluate(test_inpf)\n",
    "clear_output()\n",
    "for key in sorted(results):\n",
    "  print('%s: %0.2f' % (key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These regularized models don't perform much better than the base model. \n",
    "# Let's look at the model's weight distributions to better see the effect of the regularization.\n",
    "def get_flat_weights(model):\n",
    "  weight_names = [\n",
    "      name for name in model.get_variable_names()\n",
    "      if \"linear_model\" in name and \"Ftrl\" not in name]\n",
    "\n",
    "  weight_values = [model.get_variable_value(name) for name in weight_names]\n",
    "\n",
    "  weights_flat = np.concatenate([item.flatten() for item in weight_values], axis=0)\n",
    "\n",
    "  return weights_flat\n",
    "\n",
    "weights_flat = get_flat_weights(model)\n",
    "weights_flat_l1 = get_flat_weights(model_l1)\n",
    "weights_flat_l2 = get_flat_weights(model_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models have many zero-valued weights caused by unused hash bins (there are many more hash bins than categories in some columns). We can mask these weights when viewing the weight distributions:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
